	Лексический анализ
	|			  |
лексема			токен

Лексический анализ - процесс, в котором программа получает текст а на выход дает лексемы вида <тип лексемы, токен>
Допустим есть тип лексемы: 
KW (key word): if, do, else, while, for
ID (идентификатор): все слова из символов и подчеркиваний, не являющ. ключевыми словами 
AS: :=
OP: +, -, *, /, ==
INT: 
REAL: 

Пусть прогр.: a12 := a2 + 5 * b3 / 0.37
\_____________________________________/
<ID, a12>
<AS, :=>
<ID,  a2>
<OP, +>				<------ результат лексического анализа
<INT, 5> 					18 символов, поделены на 9 токенов
<OP, *> 
<ID, b3>
<OP, />
<REAL, 0,37>

В наше время есть проги которые генерируют лексический анализатор
На вход язык, на выход лекс. анализатор
Пример такой программы, популярной: lex, а также есть flex и clex

Основной инструмент лексического анализа - конечные автоматы
Q - входные
S - мн-во начальн
(Q, E, d, S)

Практика 16.09
Допустимые слова на основе входных-выходных состояний; в недетерменированных тоже

Задача №1:
str = a0a1a2a3...........a(l)a(l+1)...........an
Описать функцию
maxString(A-автомат, str, l - номер позиции(обрабатываем строку с символа эль)) => <True/False, m>
Автомату подается строка, и начиная с l символа подает символы в автомат, и нужно найти m = max(len(substr)) такой что
substr - строка, допустимый вход в автомат

тело ф-ии

Flag = False
m = 0, i = l
curState = q0  // если недетерминированный, то множество
if curState конечно then Flag=True 
while i <= n:
  curState = A.T[curState][str[i]] // если undeterm. то нужно обновить множество, пересечение наверное
  if curState конечно then Flag=True // при undeterm. если в множестве хотя б одно есть
  m = i - l + 1
  i++
return (Flag, m)

Будем применять эту функцию для нахождения слова в строку. Напр. дан текст, а нужно найти все
вещественные числа в тексте.

Задание №2
На вход дается текстовый файл, считать файл как единую строку и прогнать через maxString
Найти все вещественные числа в файле и вывести в отдельный файл

  Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск

  Берем k = 0, пытаемся найти первое вхождение с помощью maxString
  while k <= n :
    res, m = maxString(A, str, k)
    if res && m != 0:
      k = k + m
    else:
      k = k + 1

Примечание: числа вещественные со знаком
25   +25   -25
25.5 +25.5 -25.5
+25. -25. 25.
+.5 -.5 .7
25e5 2.e18 25e+25
.8e7 .7e-8 +.7E+5

Прим2. A = (Q, E, delta, S, F)
Определяем 1)множ. состояние, 2)вх. сигналы 3)функц. перехода, 4)нач. сост., 5)конечн. состояния

Лекция 19.09
  Сейчас:
MaxString(A, str, l) => (bool, int)
  Потом:
(Класс токенов, токен)
(KW, for)
(ID, a25_78b)
  Задача лексического анализа:
Пусть классы лексем заданы конечными автоматами, каждый автомат определяет формальный язык - набор
тех слов, которые относятся к соответствующему классу лексем
  Идентификатор: последовательность всех слов, нач. с буквы, а затем буквы, цифры, подчеркивания
a..zA..z -> a..zA..Z0..9_ (цикл)
  INT
+- -> 0..9 (цикл)
  KW
f -> o -> r -> .
e -> l -> s -> e-> .
i -> f -> .
w -> h -> i -> l -> e -> .
  Каждый класс лексем определяется своим конечным автоматом

  У каждого такого автомата есть приоритет, целое число. Чем больше число, тем выше приоритет
Если в тексте с какой-то позиции начинается токен, который допускается разными автоматами,
то относим этот токен к классу лексем с наибольшим приоритетом
Первым условием отнесения токена начиная с какой-то позиции к какому-то классу будет являться
максимальный по длину слова токен (ВОПРОС, А СДЕЛАТЬ ЭТО УМНО МОЖНО? Пробелы могут не быть? разве
                                  корректный пример while21test)
A[i], str

k = 0                         // берем длину макс. токена с k-ой позиции, текущей
while k < len(str) {
  curLex = NONE        // текущая лексема
  curPr = 0                   // текущий приоритет
  m = 0                       // максимальная длина токена с позиции k
  for each M in A {
    <res, r> = maxString(M, str, k)
    if res && m < r {
      curLex = M.Lex          // класс лексем определенный автоматом M
      curPr  = M.Pr           // приоритет класса токенов
      m = r;
    }
    else if (m == r && curPr < M.Pr) {
      curLex = M.Lex
      curPr  = M.Pr
      m = r;
    }
  }
  if m > 0 {
    <curLex, str[k, m]> 
    k = k + m
  }  
  else if (m == 0) {
    <error, str[k]>  // ошибка, символ на котором ошибка
    k = k + 1
  }
}

Автоматы будет генерировать, в т.ч. с помощью программы LEXXX
На вход подается описание лексики, [текст] на выходе программа - лексический анализатор
[набор лексем]

  Как описывается лексика?
С помощью набора регулярных выражений

    {{Что такое регулярные выражения?}}
  {Регулярный язык}
Пусть у нас есть язык L1, L2 над какими-то алфавитами
L1 U L2 = L3 // "здесь особо ничего нет и ничего интересного"(с) 

Слова: w1 и w2 
Конкатенация, w1 + w2
w1w2 = w3    // ну тут очевидно что именно

L1L2 = {w | w = ab, a из {L1}, b из {L2}} - конкатенация языков: все возможные конкатенированные слова

Степени языков
L1^1 = L1
k-ая степень языка - это всевозможные слова которые можно получить в результате конкатенации k любых слов
исходного языка
L1^0 = { eps } - пустое слово / пустая строка / пустая цепочка
L1^k = L1L^(k-1)

Итерация языка L1
        inf
L1^(*) = U L1^k 
        k=0

Положительная итерация языка L1
        inf
L1^(+) = U L1^k
        k=1

  Определение регулярного языка (мн-ва):
1) 0,         // пустое мн-во,   
   { eps },   // мн-во из пустого слова,
   { a }      // мн-во, сост. из одного одно односимвольного слова - регулярн. языки
2) Если L1 и L2 - регулярные языки, то L1 U L2, L1L2, L1^(*) - регулярные языки

Прим. L1^(+) = U L1^(k) = L1L1^(*)

Регулярный язык:
{10, 101, 01}

{ 1 } { 0 } U { 1 } { 0 } { 1 } U { 0 } { 1 }
Тоже регулярный ^

Пусть язык: { 1001, 10101, 101101, 1011101, ... }
{ 1 } { 0 } ( { eps, 1, 11, 111, ... } ) { 0 } { 1 } 
                        |
                        v
          { 1 } { 0 } { 1 }* { 0 } { 1 }

Все языки регулярные? Нет, например:
{ 0^n 1^n | n >= 1}

{ 0^n 1^m | n >= 1, m >= 1 } = { 01, 001, 0001, ... 
                                 011, 0111, 01111, ...
                                 0011, 000111, ...}
или { 0 }^(+) { 1 }^(+)

  {Регулярные выражения} - 
это аппарат, предназначенный для более краткой записи операций
над регулярными языками

1)
Рег. выражение | Рег. множество
eps            ~        { eps }
0              ~           0
a              ~         { a }   // односимвольное

2) Если gamma1 ~ L1 и gamma2 ~ L2
то gamma1|gamma2 ~ L1 U L2
(gamma1)(gamma2) ~ L1L2
(gamma1)^(*)     ~ L1^(*)

В регулярных выражениях можно опускать скобки при условии что:
а) в скобках находится лишь один символ или обозначение { eps } или обозначение { 0 } 
(если в скобках нет операции)
б) скобки можно убирать если это не приводит к изменению последовательности выполнения операций
в соответствии с приоритетами
Самый высокий приоритет: * +  // итерация
                Средний: .    // конкатенация
                 Низкий: |    // объединение

a*b(c|d|e*)*(fg)  -> скобки у fg лишние


Лекция от 03.10.2019

Рассмотрим автоматы на основе правила 1 для регулярных множеств
(1. {0}, {e}, {a})

0    |   a           e  |   a           a |   a         
-----------         ---------         ---------
-> q1|   q1         q1  |   -          q1 |  q2
                                       q2 |  -

M = ( {q1}, {a}, d, {q1}, 0 )  - автомат

2. L1 - M1 ; L2 - M2
M1 = (Q1, E1, d1, S1, F1)
M2 = (Q2, E2, d2, S2, F2)

Не теряя общности предполагаем, что
Q1 n Q2 = 0

а) M3 для объединения L1 U L2                   , _  ,       
M3 = (Q1 U Q2, E1 U E2, d3, S1 U S2, F1 U F2)  (Q U Q)______^.
                                                \v--v/---\vv/
где d3(q, a) = { d1(q, a), если q из Q1 }
               { d2(q, a), если q из Q2 }

б) M4 для конкатенации L1L2
M4 = (Q1 U Q2, E1 U E2, d4, S1, F4)

где d4(q, a) =  { d2(q, a), если q из Q2 }
                { d1(q, a), если q из Q1\F1 }
                { d1(q, a) U (U d2(r, a), (r из S2)), если q из F1 }

F4 = { F2, если S2 n F2 = 0 }
     { F1 U F2, если S2 n F2 =/= 0 }


 M1 | 0  | 1        M2  | 1  | 2       M4  | 0  | 1  |  2
--------------      -------------      -------------------
>q0 | q1 | q2      >(q3)| q5 | q4      q0  | q1 | q2 |
                                       q1  | q0 | q2 |
q1  | q0 | q2      >q4  | -  | q5      (q2)| q0 | q5 | q4,q5
(q2)| q0 | -        (q5)| q4 | -       (q3)|    | q5 | q4
                                       q4  |    |    | q5
                                       (q5)|    | q4 |

L2L1

    | 0  |  1     |  2
-------------------------
>q3 | q1 | q2,q5  | q4
>q4 |    |        | q5 
q5  | q1 | q2,q4  | 
q0  | q1 |  q2    | 
q1  | q0 |  q2    | 
(q2)| q0 |        | 


в) Построим M5 для итерации L1*
Итерации - всевозможные слова из слов исходного языка

Пусть q00 - новое состояние, которое раньше отсутствовало в автомате
M5 = (Q1 U { q00 }, E1, d5, S1 U {q00}, F1 U {q00})

d5(q, a) = { d1(q, a), если q из Q1 }
           { 0, если q = q00 }
           { d1(q, a) U (U d(r, a), r из S1), если q из F1 }

((00|11)* (01|10)(00|11)* (01|10))* (01|11)*


10.10.2019
Лекция № X

Задание №3 - генерирование лексического анализатора
  на основе класса лексем (дано)

  Входной файл (1) с описанием лексики
  Входной файл (2) с текстом, для которого надо провести лексический анализ

  Выходной файл с потоком лексем

  Формат входного файла 1:
------------------------------------------
1.           N - кол-во классов лексем
             ID:M:регулярное_выражение (идентификатор класса лексем, M - приоритет, 
             рег_в в нашем формате: 
             конкатенация - слитно, | объединение, * итерация,
             \w все символы латинского алфавита
             \W все загл. буквы латинского алфавита
             \s любые пробельные символы: пробел, возврат каретки, табуляции ( , \r, \t, \n)
             \r, \t, \n
             \d - любая цифра
             \@ - пустая цепочка,
             + положительная итерация,
             \+ символ "+", \*, \| -> просто символы
             \(, \), \\ -> просто символы ) 
            Пример, целое число: (\@|\+|-)\d+

N строк

   На выходе программа, проводящая лексический анализ


Не все можно построить с помощью рег. выражений
Рассмотрим семейство языков
Но перед этим рассмотрим такой формализм как "грамматика"

G = (N, E, P, S) 
N, E -- 2 алфавита
N - мн-во нетерминальных символов
E - мн-во терминальных символов
S - один из символов множества N, стартовый символ грамматики / начальный символ
P: 
                 *         *         *
    P    c=   (N U E) N (N U E) x (N U E) 
      подмн-во

Мн-во P - мн-во всех пар, в которых в первом элементе есть хотя бы 1 нетерминальный символ,
                          а во втором элементе любое слово
Если (а, б) из P, записывают:
     а -> б  - правило/продукция грамматики 

Если у нас есть слово w1 а w2, то => w1 б w2 по правилу нашей грамматики 

Если а1 => a2 => a3 .... = ak

       *
то a1 => ak  - рефлексивно-транзитивное замыкание, отношение выводимости
                  *
и еще, бонус, a1 => a1 (не применили ни одного правила выводимости)
               *        *
L(G) = { w из E | S => w } - 
мн-во таких слов над алфавитом терминальных символов, которые выводятся из 
начального терминала S по правилам этой грамматики
(G-грамматика)

УРА, ПРИМЕРЫ, ЕЕЕЕЕЕЕЕЕЕЕЕЕБОЙ

L = { ww | w из {0, 1}* }  :   (011 011), (01101 01101) - на самом деле слитно, просто так наглядней раздельно

Правила:
P:
S    -> T1LPPT2
L    -> LA    L -> LB
T1L  -> 
T1P  ->
T1T2 -> e
T1P  -> P0A
AP   -> P0A
BP   -> P1B
A0   -> 0A
A1   -> 1A
B0   -> 0B
B1   -> 1B
AT2  -> T2
BT2  -> T2
T10  -> 0T1
T11  -> 1T1

G = ({ S, L, T1, T2, P, A, B }, { 0, 1 }, P, S)

S => T1LPPT2 => T1LAPPT2 => T1LBAPPT2 =>
=> T1LABAPPT2 => T1LAABAPPT2 => T1LAABP0APT2 =>
=> T1LAABP0P0AT2 => T1LAABP0P0T2 => T1LAAP1B0P0T2 =>
=> T1LAAP10BP0T2 => T1LAAP10P1B0T2 => TLAAP10P10BT2 =>
                  *                  *  T1 прыгает через символы, они оба уничтожают и сами уничтожаются, магия е@@ть
=> T1LAAP10P10T2 => T1LP0010P0010T2 => 00100010  и мы получили слово из L !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

"еще один маленький примерчик"

L = { a^nb^n | n >= 1 }
P: 
S -> ab | aSb 
или иначе: S -> ab  и   S -> aSb
G = ( {S}, {a, b}, P, S )
                               
s => aSb => aaSbb => aaaSbbb => aaaabbbb - тадам, множество только из терминальных символов

Пример №3. Грамматика, которая определяет язык, 
в которой все цепочки содержат четное число нулей и четное число единиц

P:
чч S -> e  | A1 | B0 
чн A -> S1 | C0 | 
нч B -> S0 | C1
нн C -> A0 | B1

G = ( {S, A, B, C}, {0, 1}, P, S )

S => e
S => A1 => S11 => B011 => C1011 => A01011 => S101011 => 101011

Классификация грамматик по Хомскому
Грамматикой типа 0 наз-вся произвольная грамматика
Грамматикой типа 1 наз-вся грамматика, в которой любое правило имеет вид (y - гамма)
    y1Ay2 -> y1аy2         +   <контекстно-зависимая грамматика>
    A из N  ;  а из (N U E)    альфа - непустая цепочка
                   *
    y1y2 из (N U E) 
  грубо говоря все время когда применяем правила цепочка либо остается в размере либо разрастается

В грамматике 1 может присутствовать правило S -> e 
при условии что S начальный символ и S не встречается в правых частях правил

Грамматикой типа 2 наз-ся грамматика, на мн-во правил кот. накладывается ограничение:
A -> a              *     <безконтекстная (контекстно-свободная / КС-) грамматика>
A из N  a из (N U E) 
Грамматикой типа 3 наз-ся грамматика, на мн-во правил накладывается ограничение:
имеет одну из 2 форм      <леволинейная грамматика>
1) A -> Ba    A,B из N  
2) A -> a       a из E*

P.S.
Линейная грамматика - в левой части не более 1 терминала
леволинейная - этот терминал в крайней левой позиции


Если для языка L найдется грамматика типа i, то
язык, определенный данной грамматикой называется языком типа i

Любую грамматику типа 3 представляет регулярный язык
Класс языков типа 3 и класс регулярных языков совпадает

Пусть есть грамматика типа 2
G = (N, E, P, S) например, грамматика, которая определяет арифметические выражения с
операциями +, * и с сбалансированными скобками

P = 
S -> S + S | S * S | (S) | a
G = ( {S}, {+, *, (, ), a}, P, S )
S => S + S => S + S * S => S + (S) * S =>
S + (S + S) * S =>=>=>=> a + (a + a) * a

Дерево вывода
1) В корне начальный терминал
2) если вершина дерева помечена нетерминальным символом A и
в процессе к нему было применено правило ... то
у соответствующего узла дерева будет N дочерних, помеченных слева направо символами ... 

A -> a1, a2, ..., an 

        A
    / / | | \ \
  a1 a2 ....... an


            S                 
        /   |   \
        S   +   S
        |      / | \
        a     S  *  S
            / | \   |
            ( S )   a
             /|\
            S + S
            |   |
            a   a

Если контекстно-свободная грамматика такова что найдется цепочка, для которой существует
два различных дерева вывода по данной грамматике, то такая грамматика называется неоднозначной

В общем случае вопрос определения однозначности грамматики алгоритмически неразрешимая задачи
Также неразрешима задача нахождения однозначной грамматики для языка

Язык называется вещественно неоднозначным если неоднозначны все грамматики, его определяющие

Существуют приемы, позволяющие снизить неоднозначность грамматики - уменьшается шанс что
грамматика неоднозначна

Грамматика наз-ся грамматикой с циклами если существует нетерминальный символ A, для кот.
за какое-то ненулевое количество шагов получается символ A 

Левый и правый вывод цепочки
Вывод цепочки называется левым если на каждом шаге вывода очередное правило применяется к
  самому левому нетерминалу цепочки
Вывод называется правым если на каждом шаге очередное правило применяется к самому правому
  нетерминалу

[Слева сверху вниз]
Последовательность правил, примененная при левом выводе цепочки называется левым разбором цепочки
(Нисходящий)

[Слева снизу вверх]
Правым разбором называется инвертированная последовательность правил, примененных при правом выводе цепочки
                         (записана наоборот)
(Восходящий)
Зачем инвертировать?
Ну потому что от итога возвращаемся к началу


В каких случаях грамматика явно неоднозначна?
Если найдется цепочка для которой существует два левых разбора
Если найдется цепочка для которой существует два правых разбора

Контекстная-зависимая грамматика G = (N, E, P, S)
наз-ся грамматикой с левой рекурсией если в ней возможен вывод
    +
A => Aa
A из N,     
a из (N U E)*

Пример:
G = ({E, T, F}, {+, *, (, ), a}, P, E)
P: E -> E + T | T
   T -> T * F | F
   F ->  (E)  | a

Если разложить в дерево: a + a * a
То с помощью этой грамматики можно сделать это ТОЛЬКО ОДНИМ СПОСОБОМ, ОГО (постирония)

    E
   /| \
  E +  T
  |   /|\
  T  T * F
  |  |   \
  F  F    a
  |  |
  a  a

--------------------------------------------
<<<<<  Метод синтаксического анализа  >>>>>>
--------------------------------------------
Метод рекурсивного спуска
A(str, k) => <flag, m, T>
input:
str - массив, поток токенов, результат лексического анализатора
k - номер позиции в массиве str, с которой нужно рассматривать эти токены
output:
flag - начиная с k-ой позиции в строке str есть последовательность, выводимая из нетерминала A
m - из скольки символов состоит эта подпоследовательность
T - дерево вывода (или разбор) из нетерминала этой подпоследовательности из m символов

(Вот такая грамматика дана, поменяли местами в первых двух правилах вывода)
G = ({E, T, F}, {+, *, (, ), a}, P, E)
P: E -> T + E | T
   T -> F * T | F
   F ->  (E)  | a

E(str, k) = {
  <res1, m1, T1> = T(str, k); // начинается ли с k-ой позиции символ T ?
  if (!res1) return <False, 0, NULL>;
  if (str[k + m1] == '+') {   // для корректности нужно проверить что строка не конч.
    <res2, m2, T2> = E(str, k + m1 + 1);
    if (!res2) return <res1, m1, T1>;
    else return <True, m1 + m2 + 1, E -> T1 (+) T2>;
  }
  else return <res1, m1, T1>;
}

T(str, k) = {
  <res1, m1, T1> = F(str, k); // начинается ли с k-ой позиции символ T ?
  if (!res1) return <False, 0, NULL>;
  if (str[k + m1] == '*') {   // для корректности нужно проверить что строка не конч.
    <res2, m2, T2> = T(str, k + m1 + 1);
    if (!res2) return <res1, m1, T1>;
    else return <True, m1 + m2 + 1, T -> T1 (*) T2>;
  }
  else return <res1, m1, T1>;
}

T(str, k) = {
  if (!str[k] == '(') {
    <res1, m1, T1> = E(str, k + 1);
    if (!res1) return <False, 0, NULL>;
    if (str[k + m1 + 1] == ')' return <True, m1 + 2, F -> ( E )>;
    else return <False, 0, NULL>;
  } 
  if (str[k] = 'a') return <True, 1, F -> a>;
  return <False, 0, NULL>;
}

Правила грамматики вида:
A -> e            -- эпсилон-правило
A -> B, A, B из N -- цепное правило

A -> BCD | a
B -> e   | CB
C -> AD  | c
D -> e   | Ba

A => BCD => CD => C => AD => A                   АААААААААААААААААААААААААААа плохо
                                                 ведь тут есть эпсилон-правило :(

Если нет эпсилон-правил, нет цепных правил, то в грамматике цикла нет

Грамматикой наз-ся грамматика без эпсилон-правил, если эпсилон-правила в ней
отсутствуют совсем или возможно присутствует правило S -> e, при условии что
S - начальный символ грамматики и S не встречается в правых частях правил

Для любой грамматики можно построить эквивалентную грамматику без эпсилон-правил

G = (N, E, P, S)
Алгоритм:
1. Построим множество правил
    N_e = (A из N | A =>* e)
На нулевом шаге...
1) N_0 = {}
2) i = 1
3) N_i = { A из N | (A -> a) из P, a из (N_i-1)* }
4) Если N_i = N_i-1 то N_e = Ni
   Иначе i = i + 1, переход к 3)

Возьмём тот пример выше, с ABCD
N_0 = {}
N_1 = {B, D}
N_2 = {B, D}