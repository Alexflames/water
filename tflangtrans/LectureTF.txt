	Лексический анализ
	|			  |
лексема			токен

Лексический анализ - процесс, в котором программа получает текст а на выход дает лексемы вида <тип лексемы, токен>
Допустим есть тип лексемы: 
KW (key word): if, do, else, while, for
ID (идентификатор): все слова из символов и подчеркиваний, не являющ. ключевыми словами 
AS: :=
OP: +, -, *, /, ==
INT: 
REAL: 

Пусть прогр.: a12 := a2 + 5 * b3 / 0.37
\_____________________________________/
<ID, a12>
<AS, :=>
<ID,  a2>
<OP, +>				<------ результат лексического анализа
<INT, 5> 					18 символов, поделены на 9 токенов
<OP, *> 
<ID, b3>
<OP, />
<REAL, 0,37>

В наше время есть проги которые генерируют лексический анализатор
На вход язык, на выход лекс. анализатор
Пример такой программы, популярной: lex, а также есть flex и clex

Основной инструмент лексического анализа - конечные автоматы
Q - входные
S - мн-во начальн
(Q, E, d, S)

Практика 16.09
Допустимые слова на основе входных-выходных состояний; в недетерменированных тоже

Задача №1:
str = a0a1a2a3...........a(l)a(l+1)...........an
Описать функцию
maxString(A-автомат, str, l - номер позиции(обрабатываем строку с символа эль)) => <True/False, m>
Автомату подается строка, и начиная с l символа подает символы в автомат, и нужно найти m = max(len(substr)) такой что
substr - строка, допустимый вход в автомат

тело ф-ии

Flag = False
m = 0, i = l
curState = q0  // если недетерминированный, то множество
if curState конечно then Flag=True 
while i <= n:
  curState = A.T[curState][str[i]] // если undeterm. то нужно обновить множество, пересечение наверное
  if curState конечно then Flag=True // при undeterm. если в множестве хотя б одно есть
  m = i - l + 1
  i++
return (Flag, m)

Будем применять эту функцию для нахождения слова в строку. Напр. дан текст, а нужно найти все
вещественные числа в тексте.

Задание №2
На вход дается текстовый файл, считать файл как единую строку и прогнать через maxString
Найти все вещественные числа в файле и вывести в отдельный файл

  Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск | Поиск

  Берем k = 0, пытаемся найти первое вхождение с помощью maxString
  while k <= n :
    res, m = maxString(A, str, k)
    if res && m != 0:
      k = k + m
    else:
      k = k + 1

Примечание: числа вещественные со знаком
25, +25, -25,
25.5 +25.5 -25.5
+25. -25. 25.
+.5 -.5 .7
e E 25e5 2.e18 25e+25
.8e7 .7e-8 +.7E+5

Прим2. A = (Q, E, delta, S, F)
Определяем 1)множ. состояние, 2)вх. сигналы 3)функц. перехода, 4)нач. сост., 5)конечн. состояния

Лекция 19.09
  Сейчас:
MaxString(A, str, l) => (bool, int)
  Потом:
(Класс токенов, токен)
(KW, for)
(ID, a25_78b)
  Задача лексического анализа:
Пусть классы лексем заданы конечными автоматами, каждый автомат определяет формальный язык - набор
тех слов, которые относятся к соответствующему классу лексем
  Идентификатор: последовательность всех слов, нач. с буквы, а затем буквы, цифры, подчеркивания
a..zA..z -> a..zA..Z0..9_ (цикл)
  INT
+- -> 0..9 (цикл)
  KW
f -> o -> r -> .
e -> l -> s -> e-> .
i -> f -> .
w -> h -> i -> l -> e -> .
  Каждый класс лексем определяется своим конечным автоматом

  У каждого такого автомата есть приоритет, целое число. Чем больше число, тем выше приоритет
Если в тексте с какой-то позиции начинается токен, который допускается разными автоматами,
то относим этот токен к классу лексем с наибольшим приоритетом
Первым условием отнесения токена начиная с какой-то позиции к какому-то классу будет являться
максимальный по длину слова токен (ВОПРОС, А СДЕЛАТЬ ЭТО УМНО МОЖНО? Пробелы могут не быть? разве
                                  корректный пример while21test)
A[i], str

k = 0                         // берем длину макс. токена с k-ой позиции, текущей
while k < len(str) {
  curLex = NONE        // текущая лексема
  curPr = 0                   // текущий приоритет
  m = 0                       // максимальная длина токена с позиции k
  for each M in A {
    <res, r> = maxString(M, str, k)
    if res && m < r {
      curLex = M.Lex          // класс лексем определенный автоматом M
      curPr  = M.Pr           // приоритет класса токенов
      m = r;
    }
    else if (m == r && curPr < M.Pr) {
      curLex = M.Lex
      curPr  = M.Pr
      m = r;
    }
  }
  if m > 0 {
    <curLex, str[k, m]> 
    k = k + m
  }  
  else if (m == 0) {
    <error, str[k]>  // ошибка, символ на котором ошибка
    k = k + 1
  }
}

Автоматы будет генерировать, в т.ч. с помощью программы LEXXX
На вход подается описание лексики, [текст] на выходе программа - лексический анализатор
[набор лексем]

  Как описывается лексика?
С помощью набора регулярных выражений

    {{Что такое регулярные выражения?}}
  {Регулярный язык}
Пусть у нас есть язык L1, L2 над какими-то алфавитами
L1 U L2 = L3 // "здесь особо ничего нет и ничего интересного"(с) 

Слова: w1 и w2 
Конкатенация, w1 + w2
w1w2 = w3    // ну тут очевидно что именно

L1L2 = {w | w = ab, a из {L1}, b из {L2}} - конкатенация языков: все возможные конкатенированные слова

Степени языков
L1^1 = L1
k-ая степень языка - это всевозможные слова которые можно получить в результате конкатенации k любых слов
исходного языка
L1^0 = { eps } - пустое слово / пустая строка / пустая цепочка
L1^k = L1L^(k-1)

Итерация языка L1
        inf
L1^(*) = U L1^k 
        k=0

Положительная итерация языка L1
        inf
L1^(+) = U L1^k
        k=1

  Определение регулярного языка:
1) 0,         // пустое мн-во,   
   { eps },   // мн-во из пустого слова,
   { a }      // мн-во, сост. из одного одно односимвольного слова - регулярн. языки
2) Если L1 и L2 - регулярные языки, то L1 U L2, L1L2, L1^(*) - регулярные языки

Прим. L1^(+) = U L1^(k) = L1L1^(*)

Регулярный язык:
{10, 101, 01}

{ 1 } { 0 } U { 1 } { 0 } { 1 } U { 0 } { 1 }
Тоже регулярный ^

Пусть язык: { 1001, 10101, 101101, 1011101, ... }
{ 1 } { 0 } ( { eps, 1, 11, 111, ... } ) { 0 } { 1 } 
                        |
                        v
          { 1 } { 0 } { 1 }* { 0 } { 1 }

Все языки регулярные? Нет, например:
{ 0^n 1^n | n >= 1}

{ 0^n 1^m | n >= 1, m >= 1 } = { 01, 001, 0001, ... 
                                 011, 0111, 01111, ...
                                 0011, 000111, ...}
или { 0 }^(+) { 1 }^(+)

  {Регулярные выражения} - 
это аппарат, предназначенный для более краткой записи операций
над регулярными языками

1)
Рег. выражение | Рег. множество
eps            ~        { eps }
0              ~           0
a              ~         { a }   // односимвольное

2) Если gamma1 ~ L1 и gamma2 ~ L2
то gamma1|gamma2 ~ L1 U L2
(gamma1)(gamma2) ~ L1L2
(gamma1)^(*)     ~ L1^(*)

В регулярных выражениях можно опускать скобки при условии что:
а) в скобках находится лишь один символ или обозначение { eps } или обозначение { 0 } 
(если в скобках нет операции)
б) скобки можно убирать если это не приводит к изменению последовательности выполнения операций
в соответствии с приоритетами
Самый высокий приоритет: * +  // итерация
                Средний: .    // конкатенация
                 Низкий: |    // объединение

a*b(c|d|e*)*(fg)  -> скобки у fg лишние